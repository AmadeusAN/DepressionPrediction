{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:38:16.250283800Z",
     "start_time": "2024-08-03T03:38:16.242261100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:38:16.560451300Z",
     "start_time": "2024-08-03T03:38:16.541807200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 120\n",
    "V_1 = torch.randn(size=(1, k))\n",
    "V_2 = torch.randn(size=(1, k))\n",
    "V_3 = torch.randn(size=(1, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:38:18.943096700Z",
     "start_time": "2024-08-03T03:38:18.924028800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class modal_attention_network(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FirstLayer(nn.Module):\n",
    "    def __init__(self, input_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.modal_attention_network = modal_attention_network(input_dim, 1, dropout)\n",
    "\n",
    "    def forward(self, x_1, x_2, x_3):\n",
    "        a_1 = self.modal_attention_network(x_1)\n",
    "        a_2 = self.modal_attention_network(x_2)\n",
    "        a_3 = self.modal_attention_network(x_3)\n",
    "        U = 1 / 3 * torch.sum(torch.stack([a_1 * x_1, a_2 * x_2, a_3 * x_3], dim=1), dim=1)\n",
    "        return U, a_1, a_2, a_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:38:19.282343300Z",
     "start_time": "2024-08-03T03:38:19.257303800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer = FirstLayer(k, 0.5)\n",
    "U, a_1, a_2, a_3 = first_layer(V_1, V_2, V_3)\n",
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:38:20.870968200Z",
     "start_time": "2024-08-03T03:38:20.854345300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiLayerNeuralFusionNetwork(nn.Module):\n",
    "    '''\n",
    "    :input: 两种模态向量\n",
    "    :output: 双模态节点\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fusion_layer = nn.Linear(2 * input_dim, input_dim)\n",
    "\n",
    "    def forward(self, x_1, x_2):\n",
    "        return self.fusion_layer(torch.cat([x_1, x_2], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:39:02.475035300Z",
     "start_time": "2024-08-03T03:39:02.459428Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilayer_neural_fusion_network = MultiLayerNeuralFusionNetwork(k)\n",
    "multilayer_neural_fusion_network(V_1, V_2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:39:04.176624Z",
     "start_time": "2024-08-03T03:39:04.170049100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SecondLayer(nn.Module):\n",
    "    def __init__(self, k: int = 120):\n",
    "        super().__init__()\n",
    "        self.multilayer_neural_fusion_network = MultiLayerNeuralFusionNetwork(k)\n",
    "\n",
    "    def forward(self, x_1, x_2, x_3, a_1, a_2, a_3):\n",
    "        V_12 = self.multilayer_neural_fusion_network(x_1, x_2)\n",
    "        V_13 = self.multilayer_neural_fusion_network(x_1, x_3)\n",
    "        V_23 = self.multilayer_neural_fusion_network(x_2, x_3)\n",
    "\n",
    "        S_12 = x_1 @ x_2.T\n",
    "        S_13 = x_1 @ x_3.T\n",
    "        S_23 = x_2 @ x_3.T\n",
    "\n",
    "        a_12_hat = (a_1 + a_2) / (S_12 + 0.5)\n",
    "        a_13_hat = (a_1 + a_3) / (S_13 + 0.5)\n",
    "        a_23_hat = (a_2 + a_3) / (S_23 + 0.5)\n",
    "\n",
    "        a_12 = torch.exp(a_12_hat) / (torch.exp(a_13_hat) + torch.exp(a_23_hat))\n",
    "        a_13 = torch.exp(a_13_hat) / (torch.exp(a_12_hat) + torch.exp(a_23_hat))\n",
    "        a_23 = torch.exp(a_23_hat) / (torch.exp(a_12_hat) + torch.exp(a_13_hat))\n",
    "\n",
    "        B = torch.sum(torch.stack([a_12 * V_12, a_13 * V_13, a_23 * V_23], dim=1), dim=1)\n",
    "        return B, a_12, a_13, a_23, V_12, V_13, V_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:39:04.500135700Z",
     "start_time": "2024-08-03T03:39:04.488106Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "second_layer = SecondLayer()\n",
    "B, a_12, a_13, a_23, V_12, V_13, V_23 = second_layer(V_1, V_2, V_3, a_1, a_2, a_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:39:04.724326900Z",
     "start_time": "2024-08-03T03:39:04.705702800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:39:06.400787300Z",
     "start_time": "2024-08-03T03:39:06.386941300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class fusion_layer_for_thirdmodal(nn.Module):\n",
    "    def __init__(self, k: int = 120):\n",
    "        super().__init__()\n",
    "        self.multilayer_neural_fusion_network = MultiLayerNeuralFusionNetwork(k)\n",
    "\n",
    "    def forward(self, V_1, V_23, V_2, V_13, V_3, V_12, a_1, a_23, a_2, a_13, a_3, a_12):\n",
    "        V_1_23 = self.multilayer_neural_fusion_network(V_1, V_23)\n",
    "        V_2_13 = self.multilayer_neural_fusion_network(V_2, V_13)\n",
    "        V_3_12 = self.multilayer_neural_fusion_network(V_3, V_12)\n",
    "\n",
    "        S_1_23 = V_1 @ V_23.T\n",
    "        S_2_13 = V_2 @ V_13.T\n",
    "        S_3_12 = V_3 @ V_12.T\n",
    "\n",
    "        a_1_23_hat = (a_1 + a_23) / (S_1_23 + 0.5)\n",
    "        a_2_13_hat = (a_2 + a_13) / (S_2_13 + 0.5)\n",
    "        a_3_12_hat = (a_3 + a_12) / (S_3_12 + 0.5)\n",
    "        a_1_23 = torch.exp(a_1_23_hat) / (torch.exp(a_2_13_hat) + torch.exp(a_3_12_hat))\n",
    "        a_2_13 = torch.exp(a_2_13_hat) / (torch.exp(a_1_23_hat) + torch.exp(a_3_12_hat))\n",
    "        a_3_12 = torch.exp(a_3_12_hat) / (torch.exp(a_1_23_hat) + torch.exp(a_2_13_hat))\n",
    "\n",
    "        return V_1_23, V_2_13, V_3_12, a_1_23, a_2_13, a_3_12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:39:08.622921600Z",
     "start_time": "2024-08-03T03:39:08.613361900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ThirdLayer(nn.Module):\n",
    "    def __init__(self, k: int = 120):\n",
    "        super().__init__()\n",
    "        self.fusion_module_1 = SecondLayer(k)\n",
    "        self.fusion_module_2 = fusion_layer_for_thirdmodal(k)\n",
    "\n",
    "    def forward(self, V_1, V_2, V_3, V_12, V_13, V_23, a_1, a_2, a_3, a_12, a_13, a_23):\n",
    "        _, a_1213, a_1223, a_1323, V_1213, V_1223, V_1323 = self.fusion_module_1(V_12, V_13, V_23, a_12, a_13, a_23)\n",
    "        V_1_23, V_2_13, V_3_12, a_1_23, a_2_13, a_3_12 = self.fusion_module_2(V_1, V_23, V_2, V_13, V_3, V_12, a_1,\n",
    "                                                                              a_23, a_2, a_13, a_3, a_12)\n",
    "        O = torch.sum(torch.stack(\n",
    "            [a_1_23 * V_1_23, a_2_13 * V_2_13, a_3_12 * V_3_12, a_1213 * V_1213, a_1223 * V_1223, a_1323 * V_1323],\n",
    "            dim=1), dim=1)\n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T03:39:08.959306100Z",
     "start_time": "2024-08-03T03:39:08.940207300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_layer = ThirdLayer()\n",
    "O = third_layer(V_1, V_2, V_3, V_12, V_13, V_23, a_1, a_2, a_3, a_12, a_13, a_23)\n",
    "O.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6015,  0.0893,  0.2374, -0.3873,  0.3150,  0.0814,  1.3210, -0.6099,\n",
       "         -1.3153, -0.3951,  0.2140,  0.0826,  0.1556,  0.9649,  0.1026,  1.3271,\n",
       "         -0.0451, -0.4745,  0.0339, -0.7251,  0.0915, -0.5068,  0.5691,  0.5645,\n",
       "         -0.9825, -0.1342, -0.2583, -0.4383, -1.0022,  0.4898, -0.1810, -0.1723,\n",
       "          0.3781, -0.6662, -1.2945, -1.5308, -0.1813, -0.2842, -0.9219,  0.3368,\n",
       "         -1.3098, -0.4573, -0.8250,  1.3964, -1.1801, -0.2033,  0.9082, -0.1288,\n",
       "          0.1234,  1.0271, -0.5290, -0.8767,  0.4783,  0.8033, -0.4152, -0.5281,\n",
       "         -0.7501, -0.3347,  0.4673, -0.4432, -0.4431, -0.0732,  0.4266, -0.1887,\n",
       "          0.1840,  1.1373,  0.6127, -0.0106,  0.7999, -0.5460, -0.0143,  0.2430,\n",
       "         -0.2398, -0.2162,  0.1107,  0.8499, -0.2635,  0.5386,  0.3964,  0.8227,\n",
       "          2.0436,  0.9463, -0.9779, -0.1312,  0.3160,  0.0258,  2.0368, -0.8336,\n",
       "          0.2256,  1.0543,  0.2935, -0.0204, -0.4197,  0.3797,  0.0190, -1.2091,\n",
       "         -0.7152,  0.7517, -0.2827, -0.2916,  0.1369, -0.0305, -0.0764, -0.6534,\n",
       "         -0.0791,  1.0388,  0.1605,  0.0787,  0.3549,  0.3084, -0.0891, -0.0527,\n",
       "          1.6050, -1.1362,  0.1421,  0.4865,  0.7684, -1.7874,  0.2471,  0.8634]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
